{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHdzbJ/z2APUk8qK4ReQDK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yd7IjbAu-_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "%tensorflow_version 2.x\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7AmdX8GvbAM",
        "colab_type": "text"
      },
      "source": [
        "Implement the function get_random_data(w, b, mu, sigma, m) that generates random data for logisitic regression with two features features x_1 and x_2. This function should return the array data of shape (m, 2) and the array labels of shape (m, 1).\n",
        "\n",
        "The entries of the arrays should be generated as follows. For each row i in {0, 1, ..., m-1}:\n",
        "\n",
        "Choose class label c=0 with probability 1/2 and c=1 with probability 1/2.\n",
        "Choose the first feature x_1 uniformly at random in the interval [0, 1).\n",
        "Set the second feature x_2 to be x_2 = w * x_1 + b + (-1)^c * n, where the \"noise\" n is chosen according to the normal distribution with mean mu and standard deviation sigma.\n",
        "The ith row of the array data consists of the features x_1 and x_2.\n",
        "The ith entry of the vector labels is the class label c.\n",
        "Implement the function display_random_data that takes as input the above two arrays labels and data. It should create scatter plot of the 2D points stored in data. Use red dots to plot the points whose labels are 1 and blue dots to plot the points whose labels are 0.\n",
        "\n",
        "Hints: You should see that the 2D points (feature vectors) corresponding to different classes are approximately separated by the line y = w * x + b, where w and b are the parameters that you used to generate the data. Note that the smaller the parameter mu, the closer the points are to this line. Also, the larger the parameter sigma, the more points can be on the wrong side of this line.\n",
        "\n",
        "Experiment with different values of mu and sigma. Make sure that the parameter m is large enough so you have enough data points.\n",
        "\n",
        "Split the data/labels into a training set (80%) and a test set (20%).\n",
        "\n",
        "Links to the numpy documentation of the functions that can be used to draw samples according to the uniform and normal distributions:\n",
        "\n",
        "Normal distribution\n",
        "Uniform distribution\n",
        "You can learn more about the normal distribution on https://en.wikipedia.org/wiki/Normal_distribution. To gain some intuition, it would be helpful to plot the Gaussian function for different parameters mu and sigma in a seperate notebook (that you do not have to submit). Later in the semester, you will need to work with normal distribution to understand variational autoencoders.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxmywQ7WvRCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(999)\n",
        "\n",
        "def get_random_data(w, b, mu, sigma, m):\n",
        "  # labels 1 and 0 with probability of 1/2\n",
        "  c = [0 if np.random.rand(1) < .5 else 1 for x in range(m)]\n",
        "\n",
        "  # creating a new list for (-1)^c\n",
        "  alt_c = [(-1)**i for i in c]\n",
        "  noise = np.multiply(alt_c, np.random.normal(loc=mu, scale=sigma, size=m)) \n",
        "  \n",
        "  # uniform distribution [0, 1)\n",
        "  x_1 = np.random.uniform(low=0, high=1, size=m)\n",
        "\n",
        "  listy = np.multiply(w, x_1)\n",
        "  x_2 = np.add(listy, noise)\n",
        "  \n",
        "  # create an array for the colors for each class\n",
        "  \n",
        "  return x_1, x_2, c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajKZIqjLvsba",
        "colab_type": "code",
        "outputId": "8424a41e-2faf-4133-9386-9755d992c297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "def graph_random_data(w, b, mu, sigma, m):\n",
        "  x_1, x_2, c = get_random_data(w, b, mu, sigma, m)\n",
        "  fig, ax = plt.subplots(figsize=(5,5))\n",
        "\n",
        "  colors = ['blue' if c[x] == 1 else 'red' for x in range(m)]\n",
        "\n",
        "  ax.scatter(x_1, x_2, c=colors)\n",
        "  plt.show()\n",
        "\n",
        "graph_random_data(10,10,15,5,100)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAAEvCAYAAADb8HMbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcoboTTZCcb6",
        "colab_type": "text"
      },
      "source": [
        "**Problem 2**\n",
        "\n",
        "Create a Keras to implement logistic regression with two features and train it with the data generated in Problem 1. The loss should be the binary cross entropy loss. \n",
        "\n",
        "How well does the trained model separate the red and blue dots?  You can obtain the separating line determined by the model by extracting the weights from the dense layer using the function ```get_weights```. See [https://keras.io/layers/about-keras-layers/](https://keras.io/layers/about-keras-layers/).  \n",
        "\n",
        "Create a plot showing the random data, the true line used to generate the data, and the separating line of the trained model. Make sure that you describe in detail in your notebook how you proceed to obtain the separating line.\n",
        "\n",
        "Note that you have to carry out some simple steps to obtain the separating line from the model weights (the two weights and the bias term of the dense layer).  This is not immediately obvious.  It maybe helpful to take a look at the heatmap below.\n",
        "\n",
        "The trained model realizes function ```f : R^2 -> R``` that takes two features as input and outputs a number in the interval ```[0, 1]```. Use a heatmap to visualize this function.  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE9I4pX2R9OF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get data and test train split\n",
        "x_1, x_2, y = get_random_data(5,5,5,5,100)\n",
        "\n",
        "# X = (x1, x2 .... xn)T\n",
        "X = np.array([x_1, x_2]).T\n",
        "\n",
        "y = np.array(y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh-gUK6aN0y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_dim, output_dim):\n",
        "  model = keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(output_dim, input_dim=input_dim, activation='sigmoid'))\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam')\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='sgd')\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a7uegBsDIiM",
        "colab_type": "code",
        "outputId": "91c20117-59a2-41c7-8568-2b35c2ea85bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# number of inputs\n",
        "input_dim = 2\n",
        "# output dimensions (classes)\n",
        "output_dim = 1\n",
        "model = build_model(input_dim, output_dim)\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=EPOCHS)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5585\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5475\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4927\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5048\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.4817\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5126\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5071\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.5617\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5830\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5001\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5274\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5110\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.5106\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5470\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5252\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5275\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5986\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5621\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5437\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5312\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5281\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5567\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4802\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5621\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4829\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5131\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6322\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5088\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5439\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5371\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5439\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5985\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5133\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5341\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5117\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5476\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5082\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4996\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5411\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5233\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4809\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.5673\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5578\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5906\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5430\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5224\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.5097\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4768\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5325\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5497\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5232\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5399\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4938\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5792\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4870\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4909\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.5145\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5265\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.5843\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5633\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5555\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.4930\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.5989\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5158\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4810\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6375\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4718\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4947\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4898\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.4796\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5174\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 1ms/step - loss: 0.4857\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5716\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4737\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5297\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5550\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.4997\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.4916\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5508\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5852\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5150\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5122\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5159\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6559\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4975\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5213\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5229\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4840\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4694\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5041\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5032\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5708\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5779\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5510\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5622\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4699\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5150\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4837\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5089\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGVaBZ_VSOT6",
        "colab_type": "code",
        "outputId": "69fa7842-5dd0-4e68-f4be-38abbfedd2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "# make predictions\n",
        "preds = model.predict(x_test)\n",
        "\n",
        "fig, ax = plt.subplots(2, figsize=(10,5))\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "  # plot real value\n",
        "  ax[0].scatter(x_test[i][0], x_test[i][1], c='blue' if y_test[i] == 1 else 'red', label='Real')\n",
        "  # plot predictions\n",
        "  ax[1].scatter(x_test[i][0], x_test[i][1], c='blue' if preds[i] >= .5 else 'red', label='Predictions')\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAEvCAYAAACZqb84AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRsACAABIjIAFAACQ2P8DVJnfqXlf7g4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA27hRL5TWx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "671f1d3f-3d94-46ee-b5b2-ede87f896646"
      },
      "source": [
        "# draw line by obtaining weights\n",
        "\n",
        "# get weights from model\n",
        "weights = model.get_weights()\n",
        "\n",
        "# has input shape of 2, which represent our weight vector\n",
        "print(weights[0].shape)\n",
        "\n",
        "# has output shape of 1, which will represent our b\n",
        "print(weights[1].shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 1)\n",
            "(1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY_3CQ0-N9gb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "34c2642d-08f8-48a5-fd57-f411f4d232b5"
      },
      "source": [
        "# these will be the weights we use to plot our graph\n",
        "# weight vector\n",
        "print(weights[0])\n",
        "\n",
        "# bias\n",
        "print(weights[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.5490647]\n",
            " [-0.2044484]]\n",
            "[0.24660717]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SoR-Wsogiez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "09dca29a-86f6-47b6-f7f3-eea9aa6aa7a1"
      },
      "source": [
        "# create arbitrary data\n",
        "\n",
        "# find range from randomly generated data\n",
        "range_max = int(np.ceil(max(x_2)))\n",
        "range_min = int(np.floor(min(x_2)))\n",
        "\n",
        "print('range: (', range_min, ' , ', range_max, ')')\n",
        "\n",
        "# create an array to represent the space of our data\n",
        "d = np.linspace(0, 1)\n",
        "r = np.linspace(range_min, range_max)\n",
        "X = np.array([d,r])\n",
        "\n",
        "\n",
        "print('Matrix dimension check')\n",
        "print(weights[0].T.shape, ' x ', X.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range: ( -15  ,  22 )\n",
            "Matrix dimension check\n",
            "(1, 2)  x  (2, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAplbQLJimw9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7fbe5095-b393-4e2c-eac8-b1b61de8cb72"
      },
      "source": [
        "# generate labels\n",
        "\n",
        "z = np.dot(weights[0].T, X) + weights[1]\n",
        "\n",
        "# apply sigmoid function\n",
        "sigmoid = lambda x : 1/(1 + np.exp(-x)) \n",
        "\n",
        "yhat = sigmoid(z[0])\n",
        "\n",
        "# plot results\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "ax.plot(x_1, z[0])\n",
        "for i in range(len(x_train)):\n",
        "  # plot real value\n",
        "  ax.scatter(x_train[i][0], x_train[i][1], c='blue' if y_train[i] == 1 else 'red', label='Real')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3.31333320e+00  3.14774839e+00  2.98216358e+00  2.81657878e+00\n",
            "  2.65099397e+00  2.48540916e+00  2.31982435e+00  2.15423955e+00\n",
            "  1.98865474e+00  1.82306993e+00  1.65748512e+00  1.49190032e+00\n",
            "  1.32631551e+00  1.16073070e+00  9.95145894e-01  8.29561086e-01\n",
            "  6.63976279e-01  4.98391471e-01  3.32806664e-01  1.67221856e-01\n",
            "  1.63704856e-03 -1.63947759e-01 -3.29532566e-01 -4.95117374e-01\n",
            " -6.60702181e-01 -8.26286989e-01 -9.91871796e-01 -1.15745660e+00\n",
            " -1.32304141e+00 -1.48862622e+00 -1.65421103e+00 -1.81979583e+00\n",
            " -1.98538064e+00 -2.15096545e+00 -2.31655026e+00 -2.48213506e+00\n",
            " -2.64771987e+00 -2.81330468e+00 -2.97888949e+00 -3.14447429e+00\n",
            " -3.31005910e+00 -3.47564391e+00 -3.64122872e+00 -3.80681352e+00\n",
            " -3.97239833e+00 -4.13798314e+00 -4.30356795e+00 -4.46915275e+00\n",
            " -4.63473756e+00 -4.80032237e+00]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ce1edfbb7531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# plot real value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (50,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAJDCAYAAAA8QNGHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq70vulmbJEL",
        "colab_type": "text"
      },
      "source": [
        "Problem 3\n",
        "\n",
        "Use numpy to implement a logistic regression model from scratch and train it with the data generated as in Problem 1.\n",
        "\n",
        "Hints: Look at the notes on logistic regression to figure out what the gradient is of the binary cross entropy loss with respect to w and b. Note that you only have to implement stochastic gradient, that is, you do not have to write vectorized code for mini-batch gradient descent.\n",
        "\n",
        "Create a plot showing the random data, the true line used to generate the data, and the separating line of the trained model.\n",
        "\n",
        "Use a heatmap to visualize the function defined by your trained model.\n",
        "\n",
        "You also have to compute the binary cross entropy loss and accuracy on the test set.\n",
        "\n",
        "https://towardsdatascience.com/logistic-regression-from-scratch-with-numpy-da4cc3121ece?gi=5969b4744006\n",
        "\n",
        "https://www.kaggle.com/emilyhorsman/basic-logistic-regression-with-numpy\n",
        "\n",
        "https://github.com/schneider128k/machine_learning_course/blob/master/slides/logistic_regression.pdf\n",
        "\n",
        "https://towardsdatascience.com/building-a-logistic-regression-in-python-301d27367c24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWMAmBbCDL6t",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression Model\n",
        "\n",
        "$ h(x) = \\sigma(\\Theta^T x) $\n",
        "\n",
        "where $ \\sigma(x) = \\frac{1}{1+e^{-t}} $\n",
        "\n",
        "Therefore the model hypothesis is \n",
        "\n",
        "$h(x) = \\frac{1}{1 + e^{-\\Theta^Tx}}$\n",
        "\n",
        "\n",
        "### Computing Cost\n",
        "\n",
        "$ J(\\Theta) = -\\frac{1}{m} \\Sigma_{i=1}^m (y^i log(h(x^i)) + (1 - y^i) log(1-h(x^i))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmCx1XIcbKN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.optimize import fmin_tnc\n",
        "\n",
        "def sigmoid(z):\n",
        "  return 1 / (1+ np.exp(z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "  return sigmoid(z)* (1 - sigmoid(z))\n",
        "\n",
        "def net_input(theta, x):\n",
        "  # compute the weighted sum of the inputs\n",
        "  return np.dot(x, theta)\n",
        "\n",
        "def probability(theta, x):\n",
        "  # return the probability (prediction) after applying sigmoid functions\n",
        "  return sigmoid(net_input(theta,x))\n",
        "\n",
        "def squared_err(a,y):\n",
        "  return 0.5 * (a - y)**2\n",
        "\n",
        "\n",
        "\n",
        "class Model:\n",
        "  def __init__(self, X, Y):\n",
        "    # create weights\n",
        "    self.theta = np.zeros((X.shape[1], 1))\n",
        "    self.X = X\n",
        "    self.m = self.X.shape[0]\n",
        "    self.Y = np.array(Y)\n",
        "    self.parameters = self.fit()\n",
        "\n",
        "  def cost_function(self):\n",
        "      # Computes the cost function for all the training samples\n",
        "      total_cost = -(1 / self.m) * np.sum(\n",
        "          self.Y * np.log(probability(self.theta, self.X)) + (1 - self.Y) * np.log(\n",
        "              1 - probability(self.theta, self.X)))\n",
        "      return total_cost\n",
        "\n",
        "\n",
        "  def gradient(self):\n",
        "      # Computes the gradient of the cost function at the point theta\n",
        "      return (1 / self.m) * np.dot(self.X.T, sigmoid(net_input(self.theta, self.X)) - self.Y)\n",
        "\n",
        "  def fit(self):\n",
        "    opt_weights = fmin_tnc(func=self.cost_function, x0=self.theta, fprime=self.gradient, args=(self.X, self.Y.flatten()))\n",
        "    return opt_weights[0]\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TchrygYSnNg3",
        "colab_type": "code",
        "outputId": "589d38be-2d18-40ee-8e91-7895d44951fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "model = Model(X, y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b593bcaac62c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-954388a4a5e8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-954388a4a5e8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mopt_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin_tnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mopt_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/tnc.py\u001b[0m in \u001b[0;36mfmin_tnc\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, epsilon, scale, offset, messages, maxCGit, maxfun, eta, stepmx, accuracy, fmin, ftol, xtol, pgtol, rescale, disp, callback)\u001b[0m\n\u001b[1;32m    273\u001b[0m             'disp': False}\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_minimize_tnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nfev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/tnc.py\u001b[0m in \u001b[0;36m_minimize_tnc\u001b[0;34m(fun, x0, args, jac, bounds, eps, scale, offset, mesg_num, maxCGit, maxiter, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, disp, callback, **unknown_options)\u001b[0m\n\u001b[1;32m    407\u001b[0m                                         \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxCGit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxfun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                                         \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepmx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                                         xtol, pgtol, rescale, callback)\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mfunv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/tnc.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cost_function() takes 1 positional argument but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvoBThe3N7Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}